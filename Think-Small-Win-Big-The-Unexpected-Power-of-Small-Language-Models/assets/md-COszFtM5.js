import{b as r,o as a,w as i,g as t,B as e,v as u,x as p,C as l}from"./modules/vue-lJTctbT6.js";import{_ as d}from"./default.vue_vue_type_script_setup_true_lang-BZBUPL48.js";import{u as c,f as m}from"./slidev/context-Cc7LZz-m.js";import"./layoutHelper-OG7q8y4W.js";import"./index-DCmlAl_w.js";import"./modules/shiki-DuH7ThZt.js";const T={__name:"slides.md__slidev_8",setup(h){const{$clicksContext:o,$frontmatter:s}=c();return o.setup(),(_,n)=>(a(),r(d,u(p(l(m)(l(s),7))),{default:i(()=>n[0]||(n[0]=[t("h1",null,"How Inference Works in an SLM ⚙️",-1),t("ul",null,[t("li",null,[e("Inference = "),t("strong",null,"“predict the next token”"),e(", one step at a time.")]),t("li",null,[e("Each prediction depends on: "),t("ul",null,[t("li",null,[e("The "),t("strong",null,"input prompt"),e(" (tokens already generated)")]),t("li",null,[e("The model’s "),t("strong",null,"internal state"),e(" (attention context)")])])]),t("li",null,[e("The output is a "),t("strong",null,"token"),e(", decoded back into a word or part of a word.")]),t("li",null,[e("Repeats until: "),t("ul",null,[t("li",null,"A stop token is reached 🛑"),t("li",null,"Max length is hit"),t("li",null,"Or your app says “that’s enough”")])])],-1),t("p",null,[e("🔁 This is why "),t("strong",null,"token limits"),e(" matter — and why "),t("strong",null,"latency scales with input length"),e(".")],-1)])),_:1,__:[0]},16))}};export{T as default};
