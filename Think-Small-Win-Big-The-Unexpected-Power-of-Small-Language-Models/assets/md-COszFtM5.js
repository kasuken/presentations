import{b as r,o as a,w as i,g as t,B as e,v as u,x as p,C as l}from"./modules/vue-lJTctbT6.js";import{_ as d}from"./default.vue_vue_type_script_setup_true_lang-BZBUPL48.js";import{u as c,f as m}from"./slidev/context-Cc7LZz-m.js";import"./layoutHelper-OG7q8y4W.js";import"./index-DCmlAl_w.js";import"./modules/shiki-DuH7ThZt.js";const T={__name:"slides.md__slidev_8",setup(h){const{$clicksContext:o,$frontmatter:s}=c();return o.setup(),(_,n)=>(a(),r(d,u(p(l(m)(l(s),7))),{default:i(()=>n[0]||(n[0]=[t("h1",null,"How Inference Works in an SLM âš™ï¸",-1),t("ul",null,[t("li",null,[e("Inference = "),t("strong",null,"â€œpredict the next tokenâ€"),e(", one step at a time.")]),t("li",null,[e("Each prediction depends on: "),t("ul",null,[t("li",null,[e("The "),t("strong",null,"input prompt"),e(" (tokens already generated)")]),t("li",null,[e("The modelâ€™s "),t("strong",null,"internal state"),e(" (attention context)")])])]),t("li",null,[e("The output is a "),t("strong",null,"token"),e(", decoded back into a word or part of a word.")]),t("li",null,[e("Repeats until: "),t("ul",null,[t("li",null,"A stop token is reached ğŸ›‘"),t("li",null,"Max length is hit"),t("li",null,"Or your app says â€œthatâ€™s enoughâ€")])])],-1),t("p",null,[e("ğŸ” This is why "),t("strong",null,"token limits"),e(" matter â€” and why "),t("strong",null,"latency scales with input length"),e(".")],-1)])),_:1,__:[0]},16))}};export{T as default};
